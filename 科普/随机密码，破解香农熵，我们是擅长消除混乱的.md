---
title: 随机密码，破解香农熵，我们是擅长消除混乱的
date: 2023-11-26 21:39:59
description: 这段科普视频通过研究文字排列的可能性进而引导出信息论中的熵和信息量的概念
categories: 
- [科普,数学]
tags:
  - 熵
  - 概率论
  - 信息熵
top_image: https://arturia-blog-1316646580.cos.ap-shanghai.myqcloud.com/ArturiaBlogPicGo/202311262155945.jpg
cover: https://arturia-blog-1316646580.cos.ap-shanghai.myqcloud.com/ArturiaBlogPicGo/202311262147604.png
keywords:
  - 概率论
  - 熵
  - 信息熵
  - 可能性空间的坍缩
  - 负熵
---
# 免喷声明
这篇文章旨在普及知识（扩展作者知识面），内容来源于作者的资料搜集或者AI解答。由于作者并未系统学习该领域，文章中的定义和知识点可能存在解读偏差。若有错误或不足之处，敬请读者不吝赐教，以便我能不断改进和完善。感谢您的理解和支持！
# 视频信息
---

title: 随机密码，破解香农熵，我们是擅长消除混乱的
author: 科技3D视界
videoDate: 2023-11-24 13:24:53
link: [随机密码，破解香农熵，我们是擅长消除混乱的](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0)
cover: https://arturia-blog-1316646580.cos.ap-shanghai.myqcloud.com/ArturiaBlogPicGo/202311262155945.jpg
intro: 一句“吃了吗”要完全解码也不容易噢

---
# 视频摘要
- [00:19](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=19.402778)~[00:40](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=40.268831)：视频在该部分提到：如果这16个字符作为单独的空间进行计算，那么它的排列具有（16!）种可能性，而如果将一句只有6个汉字的句子放到整个汉字字符（常用字符3500个）里进行计算那么就有3500<sup>6</sup>种排列的可能性
	- 疑问：为什么与汉字字符空间进行计算就是3500<sup>6</sup>种可能性呢？
	- 解答：这里有个隐藏信息，那就是这6个字符可以从这3500个常用汉字中找到，那么第一个位置就有3500个字符，而第二个汉字无论第一个汉字选了哪个汉字，它的选择同样也有3500种可能性，因此就是3500<sup>6</sup>
- [01:03](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=63.714506)~[01:12](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=72.664998)：作者在这段视频里引用了薛定谔说过的一句话：生命以负熵为生。——选自《生命是什么？》
	- 疑问一：什么是<font color = "CC6600">「负熵」</font>？
		- 答：负熵是熵的对立，熵代表的是无序，而<font color = "CC6600">「负熵则表示是有序」</font>。
	- 疑问二：为什么”生命以负熵为生（食）
		- 答：系统（即我们所处的环境）是混乱的、无序的（熵），而我们动物为了抵抗这种混乱则必须汲取那些低熵的食物来降低大自然的熵
- [01:38](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=98.976339)~[02:03](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=123.597061)：视频作者在这一部分提到人们在对无序的信息进行排序组成有意义的句子时，这其实是一个<font color = "CC6600">「熵减」</font>的过程。前一步确定好的信息会进一步导致后序可能性空间的坍缩
	- 疑问：什么是<font color = "CC6600">「熵减」</font>？
	- 答：在信息论的背景下，熵减（或信息减）通常是指信息的不确定性减少的过程。例如当我们收到额外的信息时，我们对某个系统的了解可能会增加，而这会导致系统的熵减少，这就是熵减
- [02:44](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=164.061281)~[02:55](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=175.743285)：在这一部分下，作者提到：信息就等于可能性的坍缩。他使用了克劳德·香农的一句话来验证他的猜想：信息是能够用来消除不确定性的东西
	- 疑问：如何理解“信息是能够用来消除不确定性的东西”这句话呢？
	- 答：我们获取的信息越多对某个问题的了解也就越多，那么这样就可以减少我们某个问题的不确定性。比如，我们可以通过天气预报来知道今天下不下雨，因此可以减少我们是否需要携带雨伞的不确定性
- [03:00](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=180.029409)~[04:33](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=273.529321)：通过这一段，我们可以总结出来信息量的对数表达式：<font color = "CC6600">「-log<sub>2</sub>(1/p)」</font>。
	- 1/p：是概率的倒数，我们使用概率的倒数来表达信息量，但是这样会有问题，因此采用对数的形式
- [04:36](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=276.377214)~[05:02](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=302.800373)：通过这一段，我们可以了解到对数实际上还表示进位。例如log<sub>10</sub>100=2，这就表示在十进制中，我们可以用两个数来表达100种可能（0……99），而log<sub>2</sub>4=2则表示，在二进制中，我们可以用两个数来表达4种可能性
	- 疑问：为什么使用对数可以表示可能性？
	- AI解答：对数实际上可用于表示在给定的数字系统（进制）中表示可能性所需的最小数字单位数。这是因为对数基本上是一个反函数，它告诉我们需要用一个数（基数）的多少次方来得到另一个数。换句话说，对数可以告诉我们在特定基数的数字系统中，表示一个数所需的位数（数字单位数）。（看不懂思密达😵）
- [05:01](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=301.505741)~[05:34](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=334.785902)：“信息量又可以理解为表达信息所需的位数”，视频作者在这里举了一个例子：英文字母总共有26个，那么每个字母所需要的二进制位数就是-log<sub>2</sub>(1/26)=4.7bit。而在计算机中用一个字节Byte（8bit）来表示英文字母，简直绰绰有余。而汉字，我们假设汉字字符有两万个，则每个汉字所需要的二进制位数就是：-log<sub>2</sub>(1/20000)=14.29，所以计算机通常用两个字节（16bit）来表示一个汉字
- [05:42](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=342.473252)~[06:09](https://www.bilibili.com/video/BV1dH4y127uE?spm_id_from=333.1245.0.0#t=369.957786)：这一部分讲述了<font color = "CC6600">「信息熵公式」</font>是如何形成的。如果让每一个字符都拥有同样的位数并不是很节省空间，所以我们应该用更少的位数来表示大概率事件（因此概率越大的事件信息量就越小），而用更多的位数来表示小概率事件。在完美的情况下，我们把每个字符的理想位数乘以它们各自出现的概率，得每个字符得信息量得期望值（信息熵）：H=-∑P<sub>i</sub>log<sub>2</sub>(1/P<sub>i</sub>)
# 视频总结
视频通过探讨信息理论的基础概念，展示如何从数学和物理学的角度来理解信息的本质。首先，它介绍了概念“可能性的坍缩”和“熵减”，解释了字符排列的数学概率以及如何通过概率来计算信息量。接着，视频引用薛定谔关于生命的观点，讨论了生命如何通过降低熵来维持有序。此外，视频借助简单的数学表达式，例如信息量的对数表达式“-log2(1/p)”，来阐释信息量与概率的关系。

视频还讨论了对数函数在表示数字系统中的作用，说明了对数是如何帮助我们了解表示信息所需的位数。此外，还通过分析英文字符和汉字所需的二进制位数，来解释在计算机中信息是如何被编码的。最后，视频介绍了信息熵的概念，并通过公式“H=-∑Pilog2(1/Pi)”解释了如何计算一个信息源的信息熵。这一部分强调了为什么高概率事件应该使用较少的位数来编码，而低概率事件则需要更多位数。（时间来不及了，让AI总结了下）
# 名句记载
- yes和no是人类能表达的最小信息
- 概率越大的事件信息量就越小
# 参考链接
- [负熵_百度百科](https://baike.baidu.com/item/%E8%B4%9F%E7%86%B5/543565)
- [熵 (生物学) - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E7%86%B5_(%E7%94%9F%E7%89%A9%E5%AD%B8))
- [熵 (信息论) - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA))
- [熵与信息量 | hozen.site](https://www.hozen.site/archives/42/)
- [数学符号表 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E8%A1%A8)











